# This legacy version runs the app with typesense and qdrant together as the document indices
# Danswer is moving forward with Vespa to offer a consolidated index and a better search experience
version: '3'
services:
  api_server:
    image: danswer/danswer-backend:latest
    build:
      context: ../../backend
      dockerfile: Dockerfile
    command: >
      /bin/sh -c "alembic upgrade head &&
      echo \"Starting Danswer Api Server\" &&
      uvicorn danswer.main:app --host 0.0.0.0 --port 8080"
    depends_on:
      - relational_db
      - vector_db
      - search_engine
    restart: always
    ports:
      - "8080:8080"
    environment:
      - DOCUMENT_INDEX_TYPE=split
      - INTERNAL_MODEL_VERSION=${INTERNAL_MODEL_VERSION:-openai-chat-completion}
      - GEN_AI_MODEL_VERSION=${GEN_AI_MODEL_VERSION:-gpt-3.5-turbo}
      - GEN_AI_API_KEY=${GEN_AI_API_KEY:-}
      - GEN_AI_ENDPOINT=${GEN_AI_ENDPOINT:-}
      - GEN_AI_HOST_TYPE=${GEN_AI_HOST_TYPE:-}
      - POSTGRES_HOST=relational_db
      - QDRANT_HOST=vector_db
      - TYPESENSE_HOST=search_engine
      - TYPESENSE_API_KEY=${TYPESENSE_API_KEY:-typesense_api_key}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - AUTH_TYPE=${AUTH_TYPE:-disabled}
      - QA_TIMEOUT=${QA_TIMEOUT:-}
      - GOOGLE_OAUTH_CLIENT_ID=${GOOGLE_OAUTH_CLIENT_ID:-}
      - GOOGLE_OAUTH_CLIENT_SECRET=${GOOGLE_OAUTH_CLIENT_SECRET:-}
      - DISABLE_GENERATIVE_AI=${DISABLE_GENERATIVE_AI:-}
      - API_BASE_OPENAI=${API_BASE_OPENAI:-}
      - API_TYPE_OPENAI=${API_TYPE_OPENAI:-}
      - API_VERSION_OPENAI=${API_VERSION_OPENAI:-}
      - AZURE_DEPLOYMENT_ID=${AZURE_DEPLOYMENT_ID:-}
    volumes:
      - local_dynamic_storage:/home/storage
      - file_connector_tmp_storage:/home/file_connector_storage
      - model_cache_torch:/root/.cache/torch/
      - model_cache_nltk:/root/nltk_data/
      - model_cache_huggingface:/root/.cache/huggingface/
  background:
    image: danswer/danswer-backend:latest
    build:
      context: ../../backend
      dockerfile: Dockerfile
    command: /usr/bin/supervisord
    depends_on:
      - relational_db
      - vector_db
    restart: always
    environment:
      - DOCUMENT_INDEX_TYPE=split
      - INTERNAL_MODEL_VERSION=${INTERNAL_MODEL_VERSION:-openai-chat-completion}
      - GEN_AI_MODEL_VERSION=${GEN_AI_MODEL_VERSION:-gpt-3.5-turbo}
      - GEN_AI_API_KEY=${GEN_AI_API_KEY:-}
      - GEN_AI_ENDPOINT=${GEN_AI_ENDPOINT:-}
      - GEN_AI_HOST_TYPE=${GEN_AI_HOST_TYPE:-}
      - NUM_DOCUMENT_TOKENS_FED_TO_GENERATIVE_MODEL=${NUM_DOCUMENT_TOKENS_FED_TO_GENERATIVE_MODEL:-}
      - POSTGRES_HOST=relational_db
      - QDRANT_HOST=vector_db
      - TYPESENSE_HOST=search_engine
      - TYPESENSE_API_KEY=${TYPESENSE_API_KEY:-typesense_api_key}
      - API_BASE_OPENAI=${API_BASE_OPENAI:-}
      - API_TYPE_OPENAI=${API_TYPE_OPENAI:-}
      - API_VERSION_OPENAI=${API_VERSION_OPENAI:-}
      - AZURE_DEPLOYMENT_ID=${AZURE_DEPLOYMENT_ID:-}
      - CONTINUE_ON_CONNECTOR_FAILURE=${CONTINUE_ON_CONNECTOR_FAILURE:-}
      - NUM_INDEXING_WORKERS=${NUM_INDEXING_WORKERS:-}
      - DANSWER_BOT_SLACK_APP_TOKEN=${DANSWER_BOT_SLACK_APP_TOKEN:-}
      - DANSWER_BOT_SLACK_BOT_TOKEN=${DANSWER_BOT_SLACK_BOT_TOKEN:-}
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      - local_dynamic_storage:/home/storage
      - file_connector_tmp_storage:/home/file_connector_storage
      - model_cache_torch:/root/.cache/torch/
      - model_cache_nltk:/root/nltk_data/
      - model_cache_huggingface:/root/.cache/huggingface/
  web_server:
    image: danswer/danswer-web-server:latest
    build:
      context: ../../web
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_DISABLE_STREAMING=${NEXT_PUBLIC_DISABLE_STREAMING:-false}
    depends_on:
      - api_server
    restart: always
    environment:
      - INTERNAL_URL=http://api_server:8080
      - WEB_DOMAIN=${WEB_DOMAIN:-}
      - OAUTH_NAME=${OAUTH_NAME:-}
  relational_db:
    image: postgres:15.2-alpine
    restart: always
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-password}
    ports:
      - "5432:5432"
    volumes:
      - db_volume:/var/lib/postgresql/data
  vector_db:
    image: qdrant/qdrant:v1.3.0
    restart: always
    environment:
      - QDRANT__TELEMETRY_DISABLED=true
    ports:
      - "6333:6333"
    volumes:
      - qdrant_volume:/qdrant/storage
  search_engine:
    image: typesense/typesense:0.24.1
    restart: always
    environment:
      - TYPESENSE_API_KEY=${TYPESENSE_API_KEY:-typesense_api_key}
      - TYPESENSE_DATA_DIR=/typesense/storage
    ports:
      - "8108:8108"
    volumes:
      - typesense_volume:/typesense/storage
  nginx:
    image: nginx:1.23.4-alpine
    restart: always
    # nginx will immediately crash with `nginx: [emerg] host not found in upstream`
    # if api_server / web_server are not up 
    depends_on:
      - api_server
      - web_server
    environment:
      - DOMAIN=localhost
    ports:
      - "80:80"
      - "3000:80"  # allow for localhost:3000 usage, since that is the norm
    volumes:
      - ../data/nginx:/etc/nginx/conf.d
    command: > 
      /bin/sh -c "envsubst '$$\{DOMAIN\}' < /etc/nginx/conf.d/app.conf.template.dev > /etc/nginx/conf.d/app.conf &&
      while :; do sleep 6h & wait $${!}; nginx -s reload; done & nginx -g \"daemon off;\""
volumes:
  local_dynamic_storage:
  file_connector_tmp_storage:  # used to store files uploaded by the user temporarily while we are indexing them
  db_volume:
  qdrant_volume:
  typesense_volume:
  model_cache_torch:
  model_cache_nltk:
  model_cache_huggingface:
